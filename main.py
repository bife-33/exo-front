# -*- coding: utf-8 -*-
"""extracao_dados

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xEFeOuHVr3u4LT65sYysJIQt6Eunci4Y
"""

from google.colab import files
import pandas as pd

dados_kepler = pd.read_csv('Kepler_cumulative_2025.10.04_06.02.51 - cumulative_2025.10.04_06.02.51.csv', sep=',', na_values=["", " ", "NA", "null", "NULL", "-", "--"])
dados_kepler_filtrados = dados_kepler[dados_kepler["koi_disposition"].isin(["CONFIRMED", "FALSE POSITIVE"])]

# seleciona apenas as colunas desejadas
colunas_kepler_desejadas = [
    "koi_disposition",
    "koi_period",
    "koi_prad",
    "koi_teq",
    "koi_insol",
    "koi_steff",
    "koi_slogg",
    "koi_srad",
    "ra",
    "dec",
    "koi_kepmag",
    "koi_period_err1",
    "koi_period_err2",
    "koi_steff_err1",
    "koi_steff_err2"
]
dados_kepler_extraidos = dados_kepler_filtrados[colunas_kepler_desejadas]

print(dados_kepler_extraidos);

dados_k2 = pd.read_csv('K2_k2pandc_2025.10.04_06.03.00 - k2pandc_2025.10.04_06.03.00.csv', sep=',', na_values=["", " ", "NA", "null", "NULL", "-", "--"])
dados_k2_filtrados = dados_k2[dados_k2["disposition"].isin(["CONFIRMED", "FALSE POSITIVE"])]

# seleciona apenas as colunas desejadas
colunas_k2_desejadas = [
    "disposition",
    "pl_orbper",
    "pl_rade",
    "pl_eqt",
    "pl_insol",
    "st_teff",
    "st_logg",
    "st_rad",
    "ra",
    "dec",
    "sy_vmag",
    "pl_orbpererr1",
    "pl_orbpererr2",
    "st_tefferr1",
    "st_tefferr2"
]
dados_k2_extraidos = dados_k2_filtrados[colunas_k2_desejadas]

print(dados_k2_extraidos);

dados_tess = pd.read_csv('TESS_TOI_2025.10.04_06.02.57 - TOI_2025.10.04_06.02.57.csv', sep=',', na_values=["", " ", "NA", "null", "NULL", "-", "--"])
dados_tess_filtrados = dados_tess[dados_tess["tfopwg_disp"].isin(["PC", "KP", "FP"])]

# seleciona apenas as colunas desejadas
colunas_tess_desejadas = [
    "tfopwg_disp",
    "pl_orbper",
    "pl_rade",
    "pl_eqt",
    "pl_insol",
    "st_teff",
    "st_logg",
    "st_rad",
    "ra",
    "dec",
    "st_tmag",
    "pl_orbpererr1",
    "pl_orbpererr2",
    "st_tefferr1",
    "st_tefferr2"
]
dados_tess_extraidos = dados_tess_filtrados[colunas_tess_desejadas]

# transformação dos dados
dados_tess_extraidos["tfopwg_disp"] = dados_tess_extraidos["tfopwg_disp"].replace({
    "PC": "CONFIRMED",
    "KP": "CONFIRMED",
    "FP": "FALSE POSITIVE"
})

print(dados_tess_extraidos);

columns = [
    "Situação/Estado da validação",
    "Período orbital (dias)",
    "Raio do planeta (R⊕)",
    "Temperatura de equilíbrio (K)",
    "Insolação recebida (⊕)",
    "Temperatura efetiva (K)",
    "Gravidade superficial (log g)",
    "Raio estelar (R☉)",
    "RA",
    "DEC",
    "Magnetude",
    "Maior Período orbital",
    "Menor Período orbital",
    "Maior Temperatura efetiva",
    "Menor Temperatura efetiva"
]
dados_kepler_extraidos.columns = columns
dados_k2_extraidos.columns = columns
dados_tess_extraidos.columns = columns
dados_unificados = pd.concat([dados_kepler_extraidos, dados_k2_extraidos, dados_tess_extraidos], ignore_index=True)

# Aplica algumas limpezas e transforma alguns dados
dados_unificados = dados_unificados.dropna(how="any")
dados_unificados["Situação/Estado da validação"] = dados_unificados["Situação/Estado da validação"].replace({
    "CONFIRMED": "1",
    "FALSE POSITIVE": "0"
})

float_columns = ["Maior Período orbital", "Menor Período orbital"]
dados_unificados.loc[:, float_columns] = (
    dados_unificados[float_columns]
    .replace({r'\.': '', r',': '.'}, regex=True)
    .astype(float)
)

# salva em um novo CSV
dados_unificados.to_csv("dados_unificados.csv", index=False)
print(dados_unificados)

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt

dados_treinamento = dados_unificados.sample(n=10000, random_state=42)
dados_teste = dados_unificados.drop(dados_treinamento.index)

# Treinamento
numatributos = len(dados_treinamento.columns) - 1
atributos = list(dados_treinamento.columns[0:numatributos])

xtr = dados_treinamento[atributos]
ytr = dados_treinamento["Situação/Estado da validação"]

clf = MLPClassifier(solver='sgd', activation='tanh', hidden_layer_sizes=[50, 30], random_state=0)
predicted = cross_val_predict(clf, xtr, ytr, cv=10)
expected = ytr.values

result = clf.fit(xtr, ytr)

print(confusion_matrix(expected, predicted))
print("")
print(classification_report(expected, predicted))
#print(hidden_layer_sizes)
print(accuracy_score(expected, predicted))

xte = dados_teste[atributos]
ytr = dados_teste["Situação/Estado da validação"]

predicted = clf.predict(xte)
expected = ytr.values

print(confusion_matrix(expected, predicted))
print('')
print(classification_report(expected, predicted))
print(accuracy_score(expected, predicted))